{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CE_CNN_v4.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOCO5NwzfA+UlMviiqx5wYV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/atick-faisal/Crowd-Emotion/blob/main/src_v4/CE_CNN_v4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aplzJ78m29hE",
        "outputId": "8af01468-1c62-407d-90bd-8a256c9e8751",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import os\n",
        "import shutil\n",
        "import librosa\n",
        "import tarfile\n",
        "import requests\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "tf.__version__"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.4.1'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ENLuDQIchauJ"
      },
      "source": [
        "DATASET_ID   = '1HOe5sJe_Juf5uib4f-8pPv-Z64lmqQ4X'\n",
        "BASE_DIR     = '/content/'\n",
        "DATA_DIR     = 'Crowd-Emotion-Audio/'\n",
        "FOLDS        = ['Fold 1', 'Fold 2', 'Fold 3', 'Fold 4', 'Fold 5']\n",
        "EMOTIONS     = ['Approval', 'Disapproval', 'Neutral']\n",
        "\n",
        "Fs           = 44100\n",
        "INCREMENT    = 11025 #25%\n",
        "\n",
        "WINDOW_LEN   = 400\n",
        "FFT_LEN      = 400\n",
        "HOP_LENGTH   = 200"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jfzDEcGxh7Be"
      },
      "source": [
        "#--------------------- Download util for Google Drive ------------------- #\n",
        "\n",
        "def download_file_from_google_drive(id, destination):\n",
        "    URL = \"https://docs.google.com/uc?export=download\"\n",
        "\n",
        "    session = requests.Session()\n",
        "\n",
        "    response = session.get(URL, params = { 'id' : id }, stream = True)\n",
        "    token = get_confirm_token(response)\n",
        "\n",
        "    if token:\n",
        "        params = { 'id' : id, 'confirm' : token }\n",
        "        response = session.get(URL, params = params, stream = True)\n",
        "        \n",
        "    save_response_content(response, destination)    \n",
        "\n",
        "def get_confirm_token(response):\n",
        "    for key, value in response.cookies.items():\n",
        "        if key.startswith('download_warning'):\n",
        "            return value\n",
        "        \n",
        "    return None\n",
        "\n",
        "def save_response_content(response, destination):\n",
        "    CHUNK_SIZE = 32768\n",
        "\n",
        "    with open(destination, \"wb\") as f:\n",
        "        for chunk in response.iter_content(CHUNK_SIZE):\n",
        "            if chunk:\n",
        "                f.write(chunk)\n",
        "\n",
        "def download_data(fid, destination):\n",
        "    print('cleaning already existing files ... ', end='')\n",
        "    try:\n",
        "        shutil.rmtree(destination)\n",
        "        print('√')\n",
        "    except:\n",
        "        print('✕')\n",
        "        \n",
        "    print('creating data directory ... ', end='')\n",
        "    os.mkdir(destination)\n",
        "    print('√')\n",
        "    \n",
        "    print('downloading dataset from the repository ... ', end='')\n",
        "    filename = os.path.join(destination, 'dataset.tar.xz')\n",
        "    try:\n",
        "        download_file_from_google_drive(fid, filename)\n",
        "        print('√')\n",
        "    except:\n",
        "        print('✕')\n",
        "        \n",
        "    print('extracting the dataset ... ', end='')\n",
        "    try:\n",
        "        tar = tarfile.open(filename)\n",
        "        tar.extractall(destination)\n",
        "        tar.close()\n",
        "        print('√')\n",
        "    except:\n",
        "        print('✕')   "
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K4POPnOmiCq_",
        "outputId": "67fb50c4-3df4-4069-ce7c-0f00ea4310ec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# ------- Comment This if already downloaded -------- #\n",
        "\n",
        "destination = os.path.join(BASE_DIR, DATA_DIR)\n",
        "download_data(DATASET_ID, destination)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cleaning already existing files ... ✕\n",
            "creating data directory ... √\n",
            "downloading dataset from the repository ... √\n",
            "extracting the dataset ... √\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I2HuqjDmiHO0"
      },
      "source": [
        "count = 0\n",
        "for emotion in EMOTIONS:\n",
        "    for fold in FOLDS:\n",
        "        fold_path = os.path.join(BASE_DIR, DATA_DIR, emotion, fold)\n",
        "        filenames = os.listdir(fold_path)\n",
        "        for filename in filenames:\n",
        "            file_path = os.path.join(fold_path, filename)\n",
        "            data, _ = librosa.load(\n",
        "                path        = file_path,\n",
        "                sr          = Fs,\n",
        "                mono        = True\n",
        "            )\n",
        "\n",
        "            n = data.shape[0]\n",
        "            i = 0\n",
        "            while (i + Fs) < n:\n",
        "                x = data[i:(i + Fs)]\n",
        "                spectrogram = tf.signal.stft(\n",
        "                   signals        = x,\n",
        "                   frame_length   = WINDOW_LEN,\n",
        "                   frame_step     = HOP_LENGTH,\n",
        "                   fft_length     = FFT_LEN,\n",
        "                   window_fn      = tf.signal.hamming_window\n",
        "                )\n",
        "                \n",
        "                i = i + INCREMENT"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WqZtSlUnkyhq"
      },
      "source": [
        " s = tf.abs(spectrogram)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tojtiXTBoWOf",
        "outputId": "c3c2a468-7d9a-457e-c380-c434a7afa764",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "s.shape"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([171, 513])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pnnjfVGD3yjD"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}