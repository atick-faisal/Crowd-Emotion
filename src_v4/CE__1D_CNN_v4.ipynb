{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CE__1D_CNN_v4.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "https://github.com/atick-faisal/Crowd-Emotion/blob/main/CE__1D_CNN_v4.ipynb",
      "authorship_tag": "ABX9TyMxLdJ3Fw/R+9w90gM4KrP/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/atick-faisal/Crowd-Emotion/blob/main/src_v4/CE__1D_CNN_v4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xXm9QHXCkyPe",
        "outputId": "f6413725-c390-487f-b656-3146f78ce4d0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install -q tensorflow_io"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 25.4MB 1.8MB/s \n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l8OfY47r7HXQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "9f22d8de-1506-4907-ea97-87a9071578d2"
      },
      "source": [
        "import os\n",
        "import time\n",
        "import json\n",
        "import datetime\n",
        "\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow_io as tfio\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "tf.__version__"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.4.1'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bGoDOAEZ7PuE"
      },
      "source": [
        "CONFIG = {\n",
        "    'timestamp'             : str(datetime.datetime.now()),\n",
        "    'model'                 : 'Transfer Learning on YAMNET',\n",
        "    'test_fold'             : 'Fold 5',\n",
        "    'Fs'                    : 44100,\n",
        "    'frame_length'          : 44100,\n",
        "    'frame_step'            : 22050,\n",
        "    'architecture'          : '',\n",
        "    'batch_size'            : 32,\n",
        "    'epochs'                : 0,\n",
        "    'learning_rate'         : 0.000005,\n",
        "    'monitor'               : 'val_loss',\n",
        "    'patience'              : 3,\n",
        "    'class_weight'          : { 0: 0.71, 1:  2.32, 2: 0.86 },\n",
        "    'training_time'         : 0,\n",
        "    'testing_time'          : 0,\n",
        "    'cm_atick'              : '',\n",
        "    'cr_atick'              : '',\n",
        "    'cm_valentina'          : '',\n",
        "    'cr_valentina'          : ''\n",
        "}"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q7sAhoG87SBg"
      },
      "source": [
        "\n",
        "BASE_DIR            = os.getcwd()\n",
        "LOG_FILE            = '/content/drive/MyDrive/Research/Crowd Emotion Logs/tl_yamnet.txt'\n",
        "FOLDS               = ['Fold 1', 'Fold 2', 'Fold 3', 'Fold 4', 'Fold 5']\n",
        "EMOTIONS            = ['Approval', 'Disapproval', 'Neutral']\n",
        "\n",
        "ATICK_DATA_DIR      = '/content/Dataset-Atick/'\n",
        "VALENTINA_DATA_DIR  = '/content/Dataset-Valentina/'\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X4F05a8b7XON",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a5bf5bf-f006-4119-fa06-233664b0ffaf"
      },
      "source": [
        "%%time\n",
        "\n",
        "# # ----------------- Loading my dataset -------------------\n",
        "# !mkdir /content/Dataset-Atick/\n",
        "# !gdown --id '1HOe5sJe_Juf5uib4f-8pPv-Z64lmqQ4X'\n",
        "# !tar -xf /content/Crowd-Emotion-Dataset.tar.xz -C /content/Dataset-Atick/\n",
        "\n",
        "# # ----------------- Loading Valentina's dataset -------------------\n",
        "# !mkdir /content/Dataset-Valentina/\n",
        "# !gdown --id '11tC2Nmie9v3ljo60oQJ3sN1rVkorV-N1'\n",
        "# !tar -xf /content/Valentina_CE_Dataset.tar.xz -C /content/Dataset-Valentina/\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1HOe5sJe_Juf5uib4f-8pPv-Z64lmqQ4X\n",
            "To: /content/Crowd-Emotion-Dataset.tar.xz\n",
            "239MB [00:01, 151MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=11tC2Nmie9v3ljo60oQJ3sN1rVkorV-N1\n",
            "To: /content/Valentina_CE_Dataset.tar.xz\n",
            "352MB [00:04, 76.0MB/s]\n",
            "CPU times: user 525 ms, sys: 119 ms, total: 644 ms\n",
            "Wall time: 1min 8s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "syVM81JZ7aoW"
      },
      "source": [
        "# --------------- File loading utilities ------------------\n",
        "\n",
        "def load_wav_mono(filename):\n",
        "    file_contents = tf.io.read_file(filename)\n",
        "    wav, sample_rate = tf.audio.decode_wav(\n",
        "          file_contents,\n",
        "          desired_channels=1)\n",
        "    wav = tf.squeeze(wav, axis=-1)\n",
        "    # sample_rate = tf.cast(sample_rate, dtype=tf.int64)\n",
        "    # wav = tfio.audio.resample(wav, rate_in=sample_rate, rate_out=CONFIG['Fs'])\n",
        "    return wav\n",
        "\n",
        "def load_wav_for_map(filename, label, fold):\n",
        "  return load_wav_mono(filename), label, fold\n",
        "\n",
        "def load_ds(path, class_names, fold_names=['']):\n",
        "\n",
        "    filenames = []\n",
        "    labels = []\n",
        "    folds = []\n",
        "\n",
        "    for class_name in class_names:\n",
        "        print('processing files for ' + class_name, end=' ... ')\n",
        "\n",
        "        for fold in fold_names:\n",
        "            files_path = os.path.join(path, class_name, fold)\n",
        "\n",
        "            for filename in os.listdir(files_path):\n",
        "                filenames.append(os.path.join(files_path, filename))\n",
        "                labels.append(class_names.index(class_name))\n",
        "\n",
        "                try:\n",
        "                    folds.append(FOLDS.index(fold))\n",
        "                except ValueError:\n",
        "                    folds.append(0)\n",
        "\n",
        "        print('√')\n",
        "\n",
        "    return tf.data.Dataset.from_tensor_slices((filenames, labels, folds))"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cZduP_NI7yDc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f31551c7-278b-423d-e648-a2eab24c2fbe"
      },
      "source": [
        "files_ds_atick = load_ds(ATICK_DATA_DIR, EMOTIONS, FOLDS)\n",
        "files_ds_valentina = load_ds(VALENTINA_DATA_DIR, EMOTIONS)\n",
        "\n",
        "files_ds_atick.element_spec"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "processing files for Approval ... √\n",
            "processing files for Disapproval ... √\n",
            "processing files for Neutral ... √\n",
            "processing files for Approval ... √\n",
            "processing files for Disapproval ... √\n",
            "processing files for Neutral ... √\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorSpec(shape=(), dtype=tf.string, name=None),\n",
              " TensorSpec(shape=(), dtype=tf.int32, name=None),\n",
              " TensorSpec(shape=(), dtype=tf.int32, name=None))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O5nG3XAP70dQ",
        "outputId": "c93c54b2-0e1e-4929-e531-9f118afa38e7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "wav_ds_atick = files_ds_atick.map(load_wav_for_map)\n",
        "wav_ds_valentina = files_ds_valentina.map(load_wav_for_map)\n",
        "\n",
        "wav_ds_atick.element_spec"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorSpec(shape=(None,), dtype=tf.float32, name=None),\n",
              " TensorSpec(shape=(), dtype=tf.int32, name=None),\n",
              " TensorSpec(shape=(), dtype=tf.int32, name=None))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PfopqDwc9BGE"
      },
      "source": [
        "def get_fft_coeffs(wav):\n",
        "    wav = tf.cast(wav, tf.float32)\n",
        "    fft = tf.signal.rfft(wav)\n",
        "    return tf.abs(fft)\n",
        "\n",
        "def frames_map(wav, label, fold):\n",
        "    frames = tf.signal.frame(wav, CONFIG['frame_length'], CONFIG['frame_step'], axis=0)\n",
        "    frames = tf.expand_dims(frames, -1)\n",
        "    num_frames = tf.shape(frames)[0]\n",
        "    return (\n",
        "        frames,\n",
        "        tf.repeat(label, num_frames),\n",
        "        tf.repeat(fold, num_frames)\n",
        "    )\n",
        "\n",
        "def fft_map(frame, label, fold):\n",
        "    return get_fft_coeffs(frame), label, fold\n"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uL0GZQy9WhF7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d52f2c88-6f93-47da-9466-52ad71104dd5"
      },
      "source": [
        "frames_ds_atick = wav_ds_atick.map(frames_map).unbatch()\n",
        "frames_ds_valentina = wav_ds_valentina.map(frames_map).unbatch()\n",
        "\n",
        "frames_ds_atick.element_spec"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorSpec(shape=(44100, 1), dtype=tf.float32, name=None),\n",
              " TensorSpec(shape=(), dtype=tf.int32, name=None),\n",
              " TensorSpec(shape=(), dtype=tf.int32, name=None))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dwQHXcWE-ad-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d112fa1-59cf-4ffe-d5b0-09f25249c0a9"
      },
      "source": [
        "fft_ds_atick = frames_ds_atick.map(fft_map)\n",
        "fft_ds_valentina = frames_ds_valentina.map(fft_map)\n",
        "\n",
        "fft_ds_atick.element_spec"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorSpec(shape=(44100, 1), dtype=tf.float32, name=None),\n",
              " TensorSpec(shape=(), dtype=tf.int32, name=None),\n",
              " TensorSpec(shape=(), dtype=tf.int32, name=None))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFiAqukKDEtm"
      },
      "source": [
        "cached_ds_atick = fft_ds_atick.cache()\n",
        "cached_ds_valentina = fft_ds_valentina.cache()\n",
        "\n",
        "train_ds = cached_ds_atick.filter(\n",
        "    lambda frame, label, fold: fold != FOLDS.index(CONFIG['test_fold'])\n",
        ")\n",
        "val_ds = cached_ds_atick.filter(\n",
        "    lambda frame, label, fold: fold == FOLDS.index(CONFIG['test_fold'])\n",
        ")\n",
        "\n",
        "test_ds = cached_ds_valentina\n",
        "\n",
        "# train_ds = cached_ds_atick\n",
        "# val_ds = cached_ds_valentina\n",
        "# test_ds = cached_ds_valentina\n",
        "\n",
        "# remove the folds column now that it's not needed anymore\n",
        "remove_fold_column = lambda frame, label, fold: (frame, label)\n",
        "\n",
        "train_ds = train_ds.map(remove_fold_column)\n",
        "val_ds = val_ds.map(remove_fold_column)\n",
        "test_ds = test_ds.map(remove_fold_column)\n",
        "\n",
        "train_ds = train_ds.cache().shuffle(1000) .batch(CONFIG['batch_size']) \\\n",
        "                    .prefetch(tf.data.AUTOTUNE)\n",
        "val_ds = val_ds.cache().batch(CONFIG['batch_size']).prefetch(tf.data.AUTOTUNE)\n",
        "test_ds = test_ds.cache().batch(CONFIG['batch_size']).prefetch(tf.data.AUTOTUNE)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J4SSYZbcDh5o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "827cc3e2-e419-498c-dc06-7c0d5d21e7fb"
      },
      "source": [
        "for fft, _, _ in fft_ds_atick.take(1):\n",
        "    input_shape = fft.shape\n",
        "\n",
        "print(input_shape)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(44100, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TMNqPlsdDQWi"
      },
      "source": [
        "norm_layer = tf.keras.layers.experimental.preprocessing.Normalization()\n",
        "norm_layer.adapt(fft_ds_atick.map(lambda x, label, fold: x))\n"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a8hcdxsZYUCK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2713bee4-313a-4f89-9b00-36347ee3d680"
      },
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Input(shape=input_shape),\n",
        "    norm_layer,\n",
        "    tf.keras.layers.Conv1D(64, 3, activation='relu'),\n",
        "    tf.keras.layers.Conv1D(64, 3, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.MaxPooling1D(2),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dense(len(EMOTIONS))\n",
        "])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "normalization_1 (Normalizati (None, 44100, 1)          3         \n",
            "_________________________________________________________________\n",
            "conv1d (Conv1D)              (None, 44098, 64)         256       \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 44096, 64)         12352     \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 44096, 64)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling1d (MaxPooling1D) (None, 22048, 64)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 1411072)           0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 64)                90308672  \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 3)                 195       \n",
            "=================================================================\n",
            "Total params: 90,321,478\n",
            "Trainable params: 90,321,475\n",
            "Non-trainable params: 3\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0spOA7QYbDGP"
      },
      "source": [
        "model.compile(\n",
        "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=CONFIG['learning_rate']),\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "callback = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor=CONFIG['monitor'],\n",
        "    patience=CONFIG['patience'],\n",
        "    restore_best_weights=True\n",
        ")"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "whffQed4cCCk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d34e58f-49c9-486a-ae58-869bcc2a8550"
      },
      "source": [
        "%%time\n",
        "start_time = time.time()\n",
        "\n",
        "history = model.fit(\n",
        "    train_ds,\n",
        "    epochs              = 300,\n",
        "    validation_data     = val_ds,\n",
        "    callbacks           = callback,\n",
        "    class_weight        = CONFIG['class_weight']\n",
        ")\n",
        "\n",
        "training_time = time.time() - start_time"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/300\n",
            "187/187 [==============================] - 1102s 6s/step - loss: 0.4319 - accuracy: 0.8597 - val_loss: 1.0521 - val_accuracy: 0.5713\n",
            "Epoch 2/300\n",
            "187/187 [==============================] - 1095s 6s/step - loss: 0.6959 - accuracy: 0.6172 - val_loss: 1.0194 - val_accuracy: 0.5765\n",
            "Epoch 3/300\n",
            "133/187 [====================>.........] - ETA: 4:58 - loss: 0.6754 - accuracy: 0.6269"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y3yzpUo4cHnl"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}