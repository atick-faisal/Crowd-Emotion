{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CE_TE_MobileNet_v4.ipynb",
      "provenance": [],
      "mount_file_id": "https://github.com/atick-faisal/Crowd-Emotion/blob/main/src_v4/CE__Transfer_Learning_v4.ipynb",
      "authorship_tag": "ABX9TyNzQqZeNbFcc8mD8cutMOmv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/atick-faisal/Crowd-Emotion/blob/main/src_v4/CE__Transfer_Learning_v4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aplzJ78m29hE"
      },
      "source": [
        "import os\n",
        "import time\n",
        "import json\n",
        "import joblib\n",
        "import datetime\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "tf.__version__"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZLcNGdYIWzJN"
      },
      "source": [
        "CONFIG = {\n",
        "    'timestamp'             : str(datetime.datetime.now()),\n",
        "    'model'                 : 'mobile_net_v2',\n",
        "    'img_shape'             : (160, 160),\n",
        "    'spec_config'           : 'LOG_SPEC_W400_H200_HAMM_IMG288',\n",
        "    'test_fold'             : 'Fold 1',\n",
        "    'architecture'          : '',\n",
        "    'batch_size'            : 1024,\n",
        "    'epochs'                : 0,\n",
        "    'learning_rate'         : 0.0001,\n",
        "    'monitor'               : 'val_loss',\n",
        "    'patience'              : 3,\n",
        "    'class_weight'          : { 0: 0.71, 1:  2.32, 2: 0.86 },\n",
        "    'training_time'         : 0,\n",
        "    'testing_time'          : 0,\n",
        "    'cm_atick'              : '',\n",
        "    'cr_atick'              : '',\n",
        "    'cm_valentina'          : '',\n",
        "    'cr_valentina'          : ''\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BtjV2y_jXCXT"
      },
      "source": [
        "BASE_DIR_AF         = '/content/drive/MyDrive/Research/Crowd Emotion v4/'\n",
        "BASE_DIR_VAL        = '/content/drive/MyDrive/Research/Crowd Emotion Val/'\n",
        "DATASET_DIR         = 'Dataset_AF/'\n",
        "\n",
        "LOG_FILE            = '/content/drive/MyDrive/Research/Crowd Emotion Logs/tl_specgrams.txt'\n",
        "FOLDS               = ['Fold 1', 'Fold 2', 'Fold 3', 'Fold 4', 'Fold 5']\n",
        "EMOTIONS            = ['Approval', 'Disapproval', 'Neutral']\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G6O4NiC4UVcC"
      },
      "source": [
        "CONFIG = {\n",
        "    'BASE_DIR_AF'      : '/content/drive/MyDrive/Research/Crowd Emotion v4/',\n",
        "    'BASE_DIR_VAL'     : '/content/drive/MyDrive/Research/Crowd Emotion Val/',\n",
        "    'DATASET_DIR'      : 'Dataset_AF/',\n",
        "    'LOG_DIR'          : 'Logs/',\n",
        "    'FOLDS'            : ['Fold 1', 'Fold 2', 'Fold 3', 'Fold 4', 'Fold 5'],\n",
        "    'EMOTIONS'         : ['Approval', 'Disapproval', 'Neutral'],\n",
        "\n",
        "    'MODEL'            : 'mobile_net_v2',\n",
        "    'IMG_SIZE'         : (160, 160),\n",
        "    'DATASET_LEN'      : 14882,\n",
        "\n",
        "    'SPEC_CONFIG'      : 'LOG_SPEC_W400_H200_HAMM_IMG288',\n",
        "\n",
        "    'TEST_FOLD'        : 'Fold 1',\n",
        "    'EPOCHS'           : 10,\n",
        "    'LEARNING_RATE'    : 0.001,\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BNDbuUmAEu2m"
      },
      "source": [
        "path_AF   = os.path.join(BASE_DIR_AF, DATASET_DIR)\n",
        "X_AF      = joblib.load(path_AF + CONFIG['spec_config'] + '_X.joblib')\n",
        "y_AF      = joblib.load(path_AF + CONFIG['spec_config'] + '_y.joblib')\n",
        "f_AF      = joblib.load(path_AF + CONFIG['spec_config'] + '_f.joblib')\n",
        "c_AF      = joblib.load(path_AF + CONFIG['spec_config'] + '_f.joblib')\n",
        "\n",
        "path_VAL  = os.path.join(BASE_DIR_VAL, DATASET_DIR)\n",
        "test_X    = joblib.load(path_VAL + CONFIG['spec_config'] + '_X.joblib')\n",
        "test_y    = joblib.load(path_VAL + CONFIG['spec_config'] + '_y.joblib')\n",
        "\n",
        "mask      = (f == FOLDS.index(CONFIG['test_fold']))\n",
        "train_X   = X[~mask, :]\n",
        "train_y   = y[~mask, :]\n",
        "val_X     = X[mask, :]\n",
        "val_y     = y[mask, :]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xR6FTNvwW26_"
      },
      "source": [
        "class TransferLearning():\n",
        "    def __init__(self, base_model, input_shape, learning_rate, batch_size, epochs):\n",
        "        self.base_model = base_model\n",
        "        self.input_shape = input_shape\n",
        "        self.learning_rate = learning_rate\n",
        "        self.batch_size = batch_size\n",
        "        self.epochs = epochs\n",
        "        if base_model == 'mobile_net_v2':\n",
        "            self.base_model = tf.keras.applications.MobileNetV2(\n",
        "                input_shape     = self.input_shape,\n",
        "                include_top     = False,\n",
        "                weights         = 'imagenet'\n",
        "            )\n",
        "            self.base_model.trainable = False\n",
        "            self.preprocess = tf.keras.applications.mobilenet_v2.preprocess_input\n",
        "            self.model = None\n",
        "            self.callbacks = None\n",
        "\n",
        "    def __init_model(self, num_classes):\n",
        "        inputs = tf.keras.Input(shape=self.input_shape)\n",
        "        x = self.preprocess(inputs)\n",
        "        x = self.base_model(x, training=False)\n",
        "        x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
        "        x = tf.keras.layers.Dropout(0.2)(x)\n",
        "        outputs = tf.keras.layers.Dense(num_classes)(x)\n",
        "        self.model = tf.keras.Model(inputs, outputs)\n",
        "        self.model.compile(\n",
        "            optimizer      = tf.keras.optimizers.Adam(lr=self.learning_rate),\n",
        "            loss           = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "            metrics        = ['accuracy']\n",
        "        )\n",
        "\n",
        "    def __init_callbacks(self):\n",
        "        early_stopping = tf.keras.callbacks.EarlyStopping(\n",
        "            monitor        = 'val_loss',\n",
        "            patience       = 3,\n",
        "            verbose        = 1\n",
        "        )\n",
        "        self.callbacks = [\n",
        "                          early_stopping,\n",
        "        ]\n",
        "\n",
        "    def fit(self, train_X, train_y, val_X, val_y):\n",
        "        num_classes = np.unique(train_y).shape[0]\n",
        "        self.__init_model(num_classes)\n",
        "        self.__init_callbacks()\n",
        "        history = self.model.fit(\n",
        "            x                 = train_X,\n",
        "            y                 = train_y,\n",
        "            batch_size        = self.batch_size,\n",
        "            epochs            = self.epochs,\n",
        "            verbose           = 1,\n",
        "            validation_data   = (val_X, val_y),\n",
        "            shuffle           = True,\n",
        "            callbacks         = self.callbacks\n",
        "        )\n",
        "    \n",
        "        return self.model, history \n",
        "\n",
        "    def evaluate(self, test_X, test_y):\n",
        "        prob_model = tf.keras.Sequential([self.model, tf.keras.layers.Softmax()])\n",
        "        y_pred_hot = prob_model.predict(test_X)\n",
        "        y_pred = np.argmax(y_pred_hot, axis=1)\n",
        "        return classification_report(test_y.ravel(), y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XtywXo6EgU5m"
      },
      "source": [
        "tl = TransferLearning(\n",
        "    base_model         = 'mobile_net_v2',\n",
        "    input_shape        = CONFIG['IMG_SIZE'] + (3,),\n",
        "    learning_rate      = 0.0001,\n",
        "    batch_size         = 32,\n",
        "    epochs             = 100\n",
        ")\n",
        "model, history = tl.fit(train_X, train_y, test_X, test_y)\n",
        "result = tl.evaluate(test_X, test_y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a5bbjuXNi993"
      },
      "source": [
        "result = tl.evaluate(test_X, test_y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xggJxTv6mg1a"
      },
      "source": [
        "print(result)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5REH-8jemmsh"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}