{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CE_Dataset_Generation_v4.ipynb",
      "provenance": [],
      "mount_file_id": "https://github.com/atick-faisal/Crowd-Emotion/blob/main/src_v4/CE_Dataset_Generation_v4.ipynb",
      "authorship_tag": "ABX9TyP9GPmyyLWSD1dyxHjEczPv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/atick-faisal/Crowd-Emotion/blob/main/src_v4/CE_Dataset_Generation_v4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aplzJ78m29hE"
      },
      "source": [
        "import os\n",
        "import joblib\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from keras.preprocessing.image import load_img, img_to_array"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K9Ud30ILUEV5"
      },
      "source": [
        "BASE_DIR         = '/content/drive/MyDrive/Research/Crowd Emotion v4/'\n",
        "SPECGRAM_DIR     = 'Spectrograms/'\n",
        "DATASET_DIR      = 'Dataset/'\n",
        "FOLDS            = ['Fold 1', 'Fold 2', 'Fold 3', 'Fold 4', 'Fold 5']\n",
        "EMOTIONS         = ['Approval', 'Disapproval', 'Neutral']\n",
        "\n",
        "IMG_LEN          = 160\n",
        "IMG_SIZE         = (IMG_LEN, IMG_LEN)\n",
        "DATASET_LEN      = 14882\n",
        "\n",
        "CONFIG           = 'LOG_SPEC_W400_H200_HAMM_IMG' + str(IMG_LEN)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QKdmrXFCUl-L"
      },
      "source": [
        "X = np.zeros((DATASET_LEN, IMG_LEN, IMG_LEN, 3), dtype=np.uint8)\n",
        "y = np.zeros((DATASET_LEN, 1), dtype=np.uint8)\n",
        "f = np.zeros((DATASET_LEN, ), dtype=np.uint8)\n",
        "\n",
        "count = 0\n",
        "    \n",
        "for emotion in EMOTIONS:\n",
        "    print('loading data for ' + emotion + ' emotion' , end=' ... ')\n",
        "    emotion_path = os.path.join(BASE_DIR, SPECGRAM_DIR, emotion)\n",
        "\n",
        "    for fold in FOLDS:\n",
        "        fold_path = os.path.join(emotion_path, fold)\n",
        "\n",
        "        for filename in os.listdir(fold_path):\n",
        "            # img = cv2.imread(os.path.join(fold_path, filename))\n",
        "            # resized = cv2.resize(img, IMG_SIZE)\n",
        "            img = img_to_array(\n",
        "                load_img(\n",
        "                    os.path.join(fold_path, filename),\n",
        "                    target_size = IMG_SIZE\n",
        "                ),\n",
        "                dtype = 'uint8'\n",
        "            )\n",
        "            X[count, :] = img\n",
        "            y[count, 0] = EMOTIONS.index(emotion)\n",
        "            f[count] = FOLDS.index(fold)\n",
        "            count = count + 1\n",
        "            \n",
        "    print('âˆš')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rLuUCkunXONQ"
      },
      "source": [
        "\n",
        "# joblib.dump(X, BASE_DIR + 'X_BW_' + plane + str(IMG_SIZE) + '.joblib')\n",
        "# joblib.dump(y, BASE_DIR + 'Y_BW_' + plane + str(IMG_SIZE) + '.joblib')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}