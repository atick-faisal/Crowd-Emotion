{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Spectrogram_TL.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "https://github.com/atick-faisal/Crowd-Emotion/blob/main/src/tl-generic/Spectrogram_TL.ipynb",
      "authorship_tag": "ABX9TyOkuGNNuwuJ2wkmRxEokvwQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/atick-faisal/Crowd-Emotion/blob/main/src/tl-generic/Spectrogram_TL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BgLzP9KuQw-T",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "4b68151c-559b-4737-e70e-a0b1add2360f"
      },
      "source": [
        "import os\n",
        "import time\n",
        "import json\n",
        "import joblib\n",
        "import librosa\n",
        "import datetime\n",
        "\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import soundfile as sf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "from scipy.signal import spectrogram\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "from matplotlib.mlab import specgram\n",
        "from matplotlib.backends.backend_agg import FigureCanvasAgg as FigureCanvas\n",
        "from matplotlib.figure import Figure\n",
        "\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "tf.__version__"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.4.1'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o0Pd708wRBMJ"
      },
      "source": [
        "CONFIG = {\n",
        "    'timestamp'             : str(datetime.datetime.now()),\n",
        "    'model'                 : 'Transfer Learning on MobileNet',\n",
        "    'base_model'            : 'mobile_net_v2',\n",
        "    'input_shape'           : (160, 160, 3),\n",
        "    'test_fold'             : 'Fold 5',\n",
        "    'frame_length'          : 44100,\n",
        "    'frame_inc'             : 11025,\n",
        "    'fig_size'              : (2.23, 2.23), # 160x160\n",
        "    'architecture'          : '',\n",
        "    'batch_size'            : 32,\n",
        "    'epochs'                : 300,\n",
        "    'learning_rate'         : 0.0001,\n",
        "    'monitor'               : 'val_loss',\n",
        "    'patience'              : 10,\n",
        "    'class_weight'          : { 0: 0.71, 1:  2.32, 2: 0.86 },\n",
        "    'training_time'         : 0,\n",
        "    'testing_time'          : 0,\n",
        "    'cm_atick'              : '',\n",
        "    'cr_atick'              : '',\n",
        "    'cm_valentina'          : '',\n",
        "    'cr_valentina'          : ''\n",
        "}"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MfTlFAURRXhO"
      },
      "source": [
        "BASE_DIR            = os.getcwd()\n",
        "LOG_FILE            = '/content/drive/MyDrive/Research/Crowd Emotion Logs/tl_generic.txt'\n",
        "FOLDS               = ['Fold 1', 'Fold 2', 'Fold 3', 'Fold 4', 'Fold 5']\n",
        "EMOTIONS            = ['Approval', 'Disapproval', 'Neutral']\n",
        "\n",
        "ATICK_DATA_DIR      = '/content/Dataset-Atick/'\n",
        "VALENTINA_DATA_DIR  = '/content/Dataset-Valentina/'\n",
        "\n",
        "RANGE               = np.array([20, 20000])\n",
        "\n",
        "ATICK_DATASET_LEN   = 13806\n",
        "VAL_DATASET_LEN     = 9484"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YkHfqIYQRaq7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63687025-ce3b-4a5c-ca88-a9fd5255dcaa"
      },
      "source": [
        "%%time\n",
        "\n",
        "# # ----------------- Loading my dataset -------------------\n",
        "# !mkdir /content/Dataset-Atick/\n",
        "# !gdown --id '1zGfANn9GKi9OUMbMehkfzk_Pvhc-b68N'\n",
        "# !tar -xf /content/Atick_CE_Dataset.tar.xz -C /content/Dataset-Atick/\n",
        "\n",
        "# # ----------------- Loading Valentina's dataset -------------------\n",
        "# !mkdir /content/Dataset-Valentina/\n",
        "# !gdown --id '11tC2Nmie9v3ljo60oQJ3sN1rVkorV-N1'\n",
        "# !tar -xf /content/Valentina_CE_Dataset.tar.xz -C /content/Dataset-Valentina/\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 2 µs, sys: 0 ns, total: 2 µs\n",
            "Wall time: 5.48 µs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eOl5w57_2hjV"
      },
      "source": [
        "## Log Spectrogram"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "726GOSnC6IWI"
      },
      "source": [
        "# def generate_dataset(data_len, data_dir):\n",
        "#     X = np.zeros((data_len, 160, 160, 3), dtype=np.uint8)\n",
        "#     y = np.zeros((data_len, 1), dtype=np.uint8)\n",
        "#     f = np.zeros((data_len, ), dtype=np.uint8)\n",
        "\n",
        "#     count = 0\n",
        "\n",
        "#     for emotion in EMOTIONS:\n",
        "#         emo_path = os.path.join(BASE_DIR, data_dir, emotion)\n",
        "\n",
        "#         print('processing data for ' + emotion + ' ... ')\n",
        "\n",
        "#         for fold in ['']:\n",
        "#             fold_path = os.path.join(emo_path, fold)\n",
        "#             files = os.listdir(fold_path)\n",
        "\n",
        "#             print('processing data for ' + fold, end=' ... ')\n",
        "            \n",
        "#             for filename in files:\n",
        "#                 wav, sr = librosa.load(\n",
        "#                     path            = os.path.join(fold_path, filename),\n",
        "#                     sr              = 44100,\n",
        "#                     mono            = True\n",
        "#                 )\n",
        "#                 # wav, sr = sf.read(os.path.join(fold_path, filename))\n",
        "#                 n = len(wav)\n",
        "#                 idx = 0\n",
        "#                 while idx < (n - CONFIG['frame_length']):\n",
        "#                     frame = wav[idx:(idx + CONFIG['frame_length'])]\n",
        "#                     idx = idx + CONFIG['frame_inc']\n",
        "\n",
        "#                     fig = Figure(figsize=CONFIG['fig_size'])\n",
        "#                     canvas = FigureCanvas(fig)\n",
        "#                     ax = fig.gca()\n",
        "\n",
        "#                     ax.axis('off')\n",
        "#                     fig.tight_layout(pad=0)\n",
        "#                     ax.margins(0)\n",
        "\n",
        "#                     ax.specgram(\n",
        "#                         x               = frame,\n",
        "#                         Fs              = 44100,\n",
        "#                         window          = np.hamming(400),\n",
        "#                         NFFT            = 400,\n",
        "#                         cmap            = 'jet',\n",
        "#                         noverlap        = 200,\n",
        "#                         mode            = 'psd',\n",
        "#                         scale           = 'dB',\n",
        "#                         detrend         = None,\n",
        "#                         scale_by_freq   = True,\n",
        "#                         vmin            = -160,\n",
        "#                         vmax            = -25,\n",
        "#                         interpolation   = 'hamming'      \n",
        "#                     )\n",
        "#                     ax.set_yscale('symlog')\n",
        "#                     ax.set_ylim(RANGE)\n",
        "\n",
        "#                     fig.canvas.draw()\n",
        "#                     img = np.frombuffer(fig.canvas.tostring_rgb(), dtype=np.uint8)\n",
        "#                     img = img.reshape(fig.canvas.get_width_height()[::-1] + (3,))\n",
        "\n",
        "#                     X[count, :] = img\n",
        "#                     y[count, 0] = EMOTIONS.index(emotion)\n",
        "#                     # f[count] = FOLDS.index(fold)\n",
        "\n",
        "#                     count = count + 1\n",
        "\n",
        "#             print('√')\n",
        "\n",
        "#     return X, y, f"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_lhrzV7T2bHY"
      },
      "source": [
        "## MEL Spectrogram"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "APeUa7uF2UJg"
      },
      "source": [
        "def generate_dataset(data_len, data_dir):\n",
        "    X = np.zeros((data_len, 160, 160, 3), dtype=np.uint8)\n",
        "    y = np.zeros((data_len, 1), dtype=np.uint8)\n",
        "    f = np.zeros((data_len, ), dtype=np.uint8)\n",
        "\n",
        "    count = 0\n",
        "\n",
        "    for emotion in EMOTIONS:\n",
        "        emo_path = os.path.join(BASE_DIR, data_dir, emotion)\n",
        "\n",
        "        print('processing data for ' + emotion + ' ... ')\n",
        "\n",
        "        for fold in FOLDS:\n",
        "            fold_path = os.path.join(emo_path, fold)\n",
        "            files = os.listdir(fold_path)\n",
        "\n",
        "            print('processing data for ' + fold, end=' ... ')\n",
        "            \n",
        "            for filename in files:\n",
        "                wav, sr = librosa.load(\n",
        "                    path            = os.path.join(fold_path, filename),\n",
        "                    sr              = 44100,\n",
        "                    mono            = True\n",
        "                )\n",
        "                # wav, sr = sf.read(os.path.join(fold_path, filename))\n",
        "                n = len(wav)\n",
        "                idx = 0\n",
        "                while idx < (n - CONFIG['frame_length']):\n",
        "                    frame = wav[idx:(idx + CONFIG['frame_length'])]\n",
        "                    idx = idx + CONFIG['frame_inc']\n",
        "\n",
        "                    fig = Figure(figsize=CONFIG['fig_size'])\n",
        "                    canvas = FigureCanvas(fig)\n",
        "                    ax = fig.gca()\n",
        "\n",
        "                    ax.axis('off')\n",
        "                    fig.tight_layout(pad=0)\n",
        "                    ax.margins(0)\n",
        "\n",
        "                    S, f, t = specgram(\n",
        "                        x               = frame,\n",
        "                        NFFT            = 400,\n",
        "                        Fs              = 44100,\n",
        "                        window          = np.hamming(400),\n",
        "                        noverlap        = 200,\n",
        "                        scale_by_freq   = True,\n",
        "                        mode            = 'psd'\n",
        "                    )\n",
        "\n",
        "                    f[0] = 1e-10\n",
        "                    f = 2595 * np.log10(1 + (f / 700))\n",
        "                    range = 2595 * np.log10(1 + (RANGE / 700))\n",
        "\n",
        "                    Z = 10. * np.log10(S)\n",
        "\n",
        "                    ax.pcolormesh(t, f, Z, cmap='jet', vmin=-160,\n",
        "                                  vmax=-25, shading='gouraud')\n",
        "                    ax.axis('auto')\n",
        "                    ax.set_ylim(range)\n",
        "\n",
        "                    fig.canvas.draw()\n",
        "                    img = np.frombuffer(fig.canvas.tostring_rgb(), dtype=np.uint8)\n",
        "                    img = img.reshape(fig.canvas.get_width_height()[::-1] + (3,))\n",
        "\n",
        "                    X[count, :] = img\n",
        "                    y[count, 0] = EMOTIONS.index(emotion)\n",
        "                    # f[count] = FOLDS.index(fold)\n",
        "\n",
        "                    count = count + 1\n",
        "\n",
        "            print('√')\n",
        "\n",
        "    return X, y, f"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iNzU9AIsReSi",
        "outputId": "16a31a12-05b8-4c00-df33-3754686ed235",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%%time\n",
        "X_AF, y_AF, f_AF = generate_dataset(ATICK_DATASET_LEN, ATICK_DATA_DIR)\n",
        "# joblib.dump(X_AF, '/content/drive/MyDrive/Research/Crowd Emotion Dataset v4/X_MEL_AF.joblib')\n",
        "# joblib.dump(y_AF, '/content/drive/MyDrive/Research/Crowd Emotion Dataset v4/y_AF.joblib')\n",
        "# joblib.dump(f_AF, '/content/drive/MyDrive/Research/Crowd Emotion Dataset v4/f_AF.joblib')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "processing data for Approval ... \n",
            "processing data for Fold 1 ... "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CmPyaBwk8BT7"
      },
      "source": [
        "class TransferLearning():\n",
        "    def __init__(self, config):\n",
        "\n",
        "        self.base_model = config['base_model']\n",
        "        self.input_shape = config['input_shape']\n",
        "        self.learning_rate = config['learning_rate']\n",
        "        self.batch_size = config['batch_size']\n",
        "        self.epochs = config['epochs']\n",
        "        self.monitor = config['monitor']\n",
        "        self.patience = config['patience']\n",
        "        self.class_weight = config['class_weight']\n",
        "\n",
        "        if self.base_model == 'mobile_net_v2':\n",
        "            self.base_model = tf.keras.applications.MobileNetV2(\n",
        "                input_shape     = self.input_shape,\n",
        "                include_top     = False,\n",
        "                weights         = 'imagenet'\n",
        "            )\n",
        "            self.base_model.trainable = False\n",
        "            self.preprocess = tf.keras.applications.mobilenet_v2.preprocess_input\n",
        "            self.model = None\n",
        "            self.callbacks = None\n",
        "\n",
        "    def __init_model(self, num_classes):\n",
        "        inputs = tf.keras.Input(shape=self.input_shape)\n",
        "        x = self.preprocess(inputs)\n",
        "        x = self.base_model(x, training=False)\n",
        "        x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
        "        x = tf.keras.layers.Dropout(0.2)(x)\n",
        "        outputs = tf.keras.layers.Dense(num_classes)(x)\n",
        "        self.model = tf.keras.Model(inputs, outputs)\n",
        "        self.model.compile(\n",
        "            optimizer      = tf.keras.optimizers.Adam(lr=self.learning_rate),\n",
        "            loss           = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "            metrics        = ['accuracy']\n",
        "        )\n",
        "\n",
        "    def __init_callbacks(self):\n",
        "        early_stopping = tf.keras.callbacks.EarlyStopping(\n",
        "            monitor        = self.monitor,\n",
        "            patience       = self.patience,\n",
        "            verbose        = 1\n",
        "        )\n",
        "        self.callbacks = [\n",
        "                          early_stopping,\n",
        "        ]\n",
        "\n",
        "    def fit(self, train_X, train_y, val_X, val_y):\n",
        "        num_classes = np.unique(train_y).shape[0]\n",
        "        self.__init_model(num_classes)\n",
        "        self.__init_callbacks()\n",
        "        history = self.model.fit(\n",
        "            x                 = train_X,\n",
        "            y                 = train_y,\n",
        "            batch_size        = self.batch_size,\n",
        "            epochs            = self.epochs,\n",
        "            verbose           = 1,\n",
        "            validation_data   = (val_X, val_y),\n",
        "            shuffle           = True,\n",
        "            callbacks         = self.callbacks,\n",
        "            class_weight      = self.class_weight\n",
        "        )\n",
        "    \n",
        "        return self.model, history \n",
        "\n",
        "    def evaluate(self, test_X, test_y):\n",
        "        prob_model = tf.keras.Sequential([self.model, tf.keras.layers.Softmax()])\n",
        "        y_pred_hot = prob_model.predict(test_X)\n",
        "        y_pred = np.argmax(y_pred_hot, axis=1)\n",
        "        return classification_report(test_y.ravel(), y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "26-CsA88cJFy"
      },
      "source": [
        "X_AF = joblib.load('/content/drive/MyDrive/Research/Crowd Emotion Dataset v4/X_AF.joblib')\n",
        "y_AF = joblib.load('/content/drive/MyDrive/Research/Crowd Emotion Dataset v4/y_AF.joblib')\n",
        "f_AF = joblib.load('/content/drive/MyDrive/Research/Crowd Emotion Dataset v4/f_AF.joblib')\n",
        "\n",
        "mask      = (f_AF == FOLDS.index(CONFIG['test_fold']))\n",
        "train_X   = X_AF[~mask, :]\n",
        "train_y   = y_AF[~mask, :]\n",
        "val_X     = X_AF[mask, :]\n",
        "val_y     = y_AF[mask, :]\n",
        "\n",
        "del X_AF\n",
        "\n",
        "test_X = joblib.load('/content/drive/MyDrive/Research/Crowd Emotion Dataset v4/X_VAL.joblib')\n",
        "test_y = joblib.load('/content/drive/MyDrive/Research/Crowd Emotion Dataset v4/y_VAL.joblib')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K7xGbl6m8VQg"
      },
      "source": [
        "%%time\n",
        "start_time = time.time()\n",
        "\n",
        "tl = TransferLearning(CONFIG)\n",
        "model, history = tl.fit(train_X, train_y, val_X, val_y)\n",
        "\n",
        "training_time = time.time() - start_time\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oPGNGjQtDsJI"
      },
      "source": [
        "%%time\n",
        "\n",
        "# ---------------- Testing on valentina's data -------------------\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "loss, accuracy = model.evaluate(test_X, test_y, batch_size=CONFIG['batch_size'])\n",
        "\n",
        "print(\"Loss: \", loss)\n",
        "print(\"Accuracy: \", accuracy)\n",
        "\n",
        "testing_time = time.time() - start_time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VfOw2nEJDvl9"
      },
      "source": [
        "metrics = history.history\n",
        "plt.plot(history.epoch, metrics['loss'], metrics['val_loss'])\n",
        "plt.legend(['loss', 'val_loss'])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ae40K1uL8WIP"
      },
      "source": [
        "# ------------------ Testing on Aticks's data -----------------\n",
        "\n",
        "y_true = val_y.ravel()\n",
        "y_pred = np.argmax(model.predict(val_X), axis=1)\n",
        "\n",
        "result_atick = classification_report(y_true, y_pred)\n",
        "print(result_atick)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Li1FPC98Zmd"
      },
      "source": [
        "# confusion_mtx_atick = tf.math.confusion_matrix(y_true, y_pred) \n",
        "confusion_mtx_atick = (confusion_matrix(y_true, y_pred, normalize='true') * 100).astype('int')\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(confusion_mtx_atick, xticklabels=EMOTIONS, yticklabels=EMOTIONS, \n",
        "            annot=True, fmt='g')\n",
        "plt.xlabel('Prediction')\n",
        "plt.ylabel('Label')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RUV9XP3sD0r_"
      },
      "source": [
        "# ------------------ Testing on Valentina's data -----------------\n",
        "\n",
        "y_true = test_y.ravel()\n",
        "y_pred = np.argmax(model.predict(test_X), axis=1)\n",
        "\n",
        "result_valentina = classification_report(y_true, y_pred)\n",
        "print(result_valentina)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UMdCnba2D2S8"
      },
      "source": [
        "# confusion_mtx_valentina = tf.math.confusion_matrix(y_true, y_pred) \n",
        "confusion_mtx_valentina = (confusion_matrix(y_true, y_pred, normalize='true') * 100).astype('int')\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(confusion_mtx_valentina, xticklabels=EMOTIONS, yticklabels=EMOTIONS, \n",
        "            annot=True, fmt='g')\n",
        "plt.xlabel('Prediction')\n",
        "plt.ylabel('Label')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ksrYabJbD2_3"
      },
      "source": [
        "summary = []\n",
        "model.summary(print_fn=lambda x: summary.append(x))\n",
        "CONFIG['architecture'] = summary\n",
        "CONFIG['epochs'] = max(history.epoch)\n",
        "CONFIG['training_time'] = training_time\n",
        "CONFIG['testing_time'] = testing_time\n",
        "CONFIG['cm_atick'] = np.array2string(confusion_mtx_atick)\n",
        "result_list_atick = result_atick.split('\\n')\n",
        "CONFIG['cr_atick'] = result_list_atick\n",
        "CONFIG['cm_valentina'] = np.array2string(confusion_mtx_valentina)\n",
        "result_list_valentina = result_valentina.split('\\n')\n",
        "CONFIG['cr_valentina'] = result_list_valentina"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aRJr9nzPD6SQ"
      },
      "source": [
        "config = json.dumps(CONFIG, indent=4)\n",
        "print(config)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MgKvnCoaD8An"
      },
      "source": [
        "f = open(LOG_FILE, 'a')\n",
        "f.write('\\n')\n",
        "f.write(config)\n",
        "f.write('\\n')\n",
        "f.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uoFuY80bZv_p"
      },
      "source": [
        "wav, sr = librosa.load(\n",
        "    path            = '/content/Dataset-Valentina/Approval/appl0000.wav',\n",
        "    sr              = 44100,\n",
        "    mono            = True\n",
        ")\n",
        "# wav, sr = sf.read(os.path.join(fold_path, filename))\n",
        "n = len(wav)\n",
        "idx = 0\n",
        "while idx < (n - CONFIG['frame_length']):\n",
        "    frame = wav[idx:(idx + CONFIG['frame_length'])]\n",
        "    idx = idx + CONFIG['frame_inc']\n",
        "\n",
        "    fig = Figure(figsize=CONFIG['fig_size'])\n",
        "    canvas = FigureCanvas(fig)\n",
        "    ax = fig.gca()\n",
        "\n",
        "    ax.axis('off')\n",
        "    fig.tight_layout(pad=0)\n",
        "    ax.margins(0)\n",
        "\n",
        "    spec, f1, t1, _ = ax.specgram(\n",
        "        x               = frame,\n",
        "        Fs              = 44100,\n",
        "        window          = np.hamming(400),\n",
        "        NFFT            = 400,\n",
        "        cmap            = 'jet',\n",
        "        noverlap        = 200,\n",
        "        mode            = 'psd',\n",
        "        scale           = 'dB',\n",
        "        detrend         = None,\n",
        "        scale_by_freq   = True,\n",
        "        vmin            = -160,\n",
        "        vmax            = -25,\n",
        "        # interpolation   = 'hamming'      \n",
        "    )\n",
        "    ax.set_yscale('symlog')\n",
        "    ax.set_ylim(RANGE)\n",
        "\n",
        "    fig.canvas.draw()\n",
        "    img = np.frombuffer(fig.canvas.tostring_rgb(), dtype=np.uint8)\n",
        "    img = img.reshape(fig.canvas.get_width_height()[::-1] + (3,))\n",
        "\n",
        "    break\n",
        "\n",
        "plt.figure(figsize=(7, 7))\n",
        "plt.imshow(img)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JXaeFw_3aFhj"
      },
      "source": [
        "wav, sr = librosa.load(\n",
        "    path            = '/content/Dataset-Valentina/Approval/appl0000.wav',\n",
        "    sr              = 44100,\n",
        "    mono            = True\n",
        ")\n",
        "# wav, sr = sf.read(os.path.join(fold_path, filename))\n",
        "n = len(wav)\n",
        "idx = 0\n",
        "while idx < (n - CONFIG['frame_length']):\n",
        "    frame = wav[idx:(idx + CONFIG['frame_length'])]\n",
        "    idx = idx + CONFIG['frame_inc']\n",
        "\n",
        "    fig = Figure(figsize=CONFIG['fig_size'])\n",
        "    canvas = FigureCanvas(fig)\n",
        "    ax = fig.gca()\n",
        "\n",
        "    ax.axis('off')\n",
        "    fig.tight_layout(pad=0)\n",
        "    ax.margins(0)\n",
        "\n",
        "    S, f, t = specgram(\n",
        "        x               = frame,\n",
        "        NFFT            = 400,\n",
        "        Fs              = 44100,\n",
        "        window          = np.hamming(400),\n",
        "        noverlap        = 200,\n",
        "        scale_by_freq   = True,\n",
        "        mode            = 'psd'\n",
        "    )\n",
        "\n",
        "    # f, t, S = spectrogram(\n",
        "    #     x               = frame,\n",
        "    #     fs              = 44100,\n",
        "    #     window          = np.hamming(400),\n",
        "    #     nperseg         = 400,\n",
        "    #     noverlap        = 200,\n",
        "    #     nfft            = 400\n",
        "    # )\n",
        "\n",
        "\n",
        "    f[0] = 1e-10\n",
        "    # f = np.log10(f)\n",
        "    f = 2595 * np.log10(1 + (f / 700))\n",
        "    range = 2595 * np.log10(1 + (RANGE / 700))\n",
        "\n",
        "    Z = 10. * np.log10(S)\n",
        "    # Z = np.flipud(Z)\n",
        "\n",
        "    pad_xextent = (400 - 200) / 44100 / 2\n",
        "    xextent = np.min(t) - pad_xextent, np.max(t) + pad_xextent\n",
        "\n",
        "    xmin, xmax = xextent\n",
        "    extent = xmin, xmax, f[0], f[-1]\n",
        "\n",
        "    # ax.imshow(Z, extent=extent, cmap='jet', origin='upper')\n",
        "    ax.pcolormesh(t, f, Z, cmap='jet', vmin=-160, vmax=-25, shading='gouraud')\n",
        "\n",
        "    ax.axis('auto')\n",
        "\n",
        "    # ax.set_yscale('symlog')\n",
        "    ax.set_ylim(range)\n",
        "\n",
        "    fig.canvas.draw()\n",
        "    img = np.frombuffer(fig.canvas.tostring_rgb(), dtype=np.uint8)\n",
        "    img = img.reshape(fig.canvas.get_width_height()[::-1] + (3,))\n",
        "\n",
        "    break\n",
        "\n",
        "plt.figure(figsize=(7, 7))\n",
        "plt.imshow(img)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vSdP0PGfbKBB"
      },
      "source": [
        "img.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fSr8z0ase7-w"
      },
      "source": [
        "f1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2vKt8TIljVIf"
      },
      "source": [
        "t2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-nj9-1-amJ0U"
      },
      "source": [
        "np.log10(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rKVIsxqesAKN"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}