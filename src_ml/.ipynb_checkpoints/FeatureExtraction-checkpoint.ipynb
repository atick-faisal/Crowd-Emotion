{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "facial-session",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import joblib\n",
    "import librosa as lb\n",
    "import scipy as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "disabled-removal",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "BASE_DIR            = os.getcwd()\n",
    "LOG_FILE            = '/content/drive/MyDrive/Research/Crowd Emotion Logs/tl_yamnet.txt'\n",
    "FOLDS               = ['Fold 1', 'Fold 2', 'Fold 3', 'Fold 4', 'Fold 5']\n",
    "EMOTIONS            = ['Approval', 'Disapproval', 'Neutral']\n",
    "\n",
    "WINDOWS_DIR         = '../Windows/'\n",
    "FEATURES_DIR        = '../Features/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "explicit-defensive",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlation(x):\n",
    "    cor = []\n",
    "    for n in range(x.shape[0]):\n",
    "        cor.append(np.correlate(x[n, :], x[n, :])[0])\n",
    "    return np.array(cor)\n",
    "\n",
    "\n",
    "def mean_crossing_rate(x):\n",
    "    mcr = []\n",
    "    for n in range(x.shape[0]):\n",
    "        mcr.append(lb.feature.zero_crossing_rate(x[n, :] - np.mean(x[n, :]))[0, 0])\n",
    "    return np.array(mcr)\n",
    "\n",
    "\n",
    "def get_entropy(x, axis = 1):\n",
    "    x = x / np.sum(x, axis = axis, keepdims=True)\n",
    "    entropy = np.sum(sp.special.entr(x), axis = axis)\n",
    "    return entropy\n",
    "\n",
    "\n",
    "def number_of_peaks(x):\n",
    "    npk = []\n",
    "    for n in range(x.shape[0]):\n",
    "        thres = (np.max(x[n, :]) / 3)\n",
    "        peaks, _ = sp.signal.find_peaks(x[n, :], thres)\n",
    "        npk.append(len(peaks))\n",
    "    return np.array(npk, dtype=float)\n",
    "\n",
    "\n",
    "def get_stat_features(x, axis=1, prefix=''):\n",
    "    min = np.min(x, axis = axis)\n",
    "    max = np.max(x, axis = axis)\n",
    "    std = np.std(x, axis = axis)\n",
    "    avg = np.mean(x, axis = axis)\n",
    "    var = np.var(x, axis = axis)\n",
    "    ptp = np.ptp(x, axis = axis)\n",
    "    mrc = np.max(np.diff(x, axis = axis), axis = axis)\n",
    "    arc = np.mean(np.diff(x, axis = axis), axis = axis)\n",
    "    src = np.std(np.diff(x, axis = axis), axis = axis)\n",
    "    mad = sp.stats.median_abs_deviation(x, axis = axis)\n",
    "    iqr = sp.stats.iqr(x, axis = axis)\n",
    "    cor = correlation(x)\n",
    "    mcr = mean_crossing_rate(x)\n",
    "    rms = np.sum(np.square(x), axis = axis)\n",
    "\n",
    "    feature_names = ['min', 'max', 'std', 'avg', 'var', \n",
    "                   'ptp', 'mrc', 'arc', 'src', 'mad', \n",
    "                   'iqr', 'cor', 'mcr', 'rms']\n",
    "    columnName = [prefix + '_' + sub for sub in feature_names]\n",
    "\n",
    "    stat_features = pd.DataFrame(np.stack((min, max, std, avg, \n",
    "                                         var, ptp, mrc, arc, \n",
    "                                         src, mad, iqr, cor, \n",
    "                                         mcr, rms), axis=1), columns=columnName)\n",
    "\n",
    "    return stat_features\n",
    " \n",
    "\n",
    "def get_freq_features(x, axis=1, fs=44100, nperseg=8000, prefix='psd'):\n",
    "    freq, psd = sp.signal.welch(x, fs, nperseg = nperseg, axis = axis)\n",
    "    mpw = np.max(psd, axis = axis)\n",
    "    ent = get_entropy(psd, axis = axis)\n",
    "    ctf = np.divide(np.sum((freq * psd), axis = axis), np.sum(psd, axis = axis))\n",
    "    mxf = np.argmax(psd, axis = axis)\n",
    "    enr = np.sum(np.square(psd), axis = axis) / nperseg\n",
    "    skw = sp.stats.skew(x, axis = axis)\n",
    "    kut = sp.stats.kurtosis(x, axis = axis)\n",
    "    npk = number_of_peaks(psd)\n",
    "\n",
    "    feature_names = ['mpw', 'ent', 'ctf', 'mxf', 'enr', 'skw', 'kut', 'npk']\n",
    "    columnName = [prefix + '_' + sub for sub in feature_names]\n",
    "\n",
    "    freq_features = pd.DataFrame(np.stack((mpw, ent, ctf, mxf, enr, skw, \n",
    "                                         kut, npk), axis=1), columns=columnName)\n",
    "\n",
    "    return freq_features\n",
    "\n",
    "\n",
    "def get_mutual_features(x, y, z, axis=1, nperseg=150, prefix=''):\n",
    "    cxy = []\n",
    "    cxz = []\n",
    "    cyz = []\n",
    "    vxy = []\n",
    "    vxz = []\n",
    "    vyz = []\n",
    "    for n in range(x.shape[0]):\n",
    "        cxy.append(np.corrcoef(x[n, :].ravel(), y[n, :].ravel())[0, 1])\n",
    "        cxz.append(np.corrcoef(x[n, :].ravel(), z[n, :].ravel())[0, 1])\n",
    "        cyz.append(np.corrcoef(y[n, :].ravel(), z[n, :].ravel())[0, 1])\n",
    "        vxy.append(np.cov(x[n, :].ravel(), y[n, :].ravel())[0, 1])\n",
    "        vxz.append(np.cov(x[n, :].ravel(), z[n, :].ravel())[0, 1])\n",
    "        vyz.append(np.cov(y[n, :].ravel(), z[n, :].ravel())[0, 1])\n",
    "    cxy = np.array(cxy)\n",
    "    cxz = np.array(cxz)\n",
    "    cyz = np.array(cyz)\n",
    "    vxy = np.array(vxy)\n",
    "    vxz = np.array(vxz)\n",
    "    vyz = np.array(vyz)\n",
    "    sma = (np.trapz(x, axis = axis) + np.trapz(x, axis = axis) + np.trapz(x, axis = axis)) / nperseg\n",
    "\n",
    "    feature_names = ['cxy', 'cxz', 'cyz', 'vxy', 'vxz', 'vyz', 'sma']\n",
    "    columnName = [prefix + '_' + sub for sub in feature_names]\n",
    "\n",
    "    mutual_features = pd.DataFrame(np.stack((cxy, cxz, cyz, vxy, vxz, vyz, sma), \n",
    "                                        axis=1), columns=columnName)\n",
    "\n",
    "    return mutual_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "german-cookbook",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.join(BASE_DIR, WINDOWS_DIR)\n",
    "\n",
    "X = pd.DataFrame()\n",
    "\n",
    "for emotion in EMOTIONS:\n",
    "    print('Processing data for ' + emotion, end=' ... ')\n",
    "    \n",
    "    for fold in FOLDS:\n",
    "        fold_path = os.path.join(path, emotion, fold)\n",
    "        filenames = os.listdir(fold_path)\n",
    "        \n",
    "        for filename in filenames:\n",
    "            file_path = os.path.join(fold_path, filename)\n",
    "            data = joblib.load(file_path)\n",
    "            \n",
    "            clip_features = get_freq_features(data)\n",
    "            \n",
    "            e_idx = EMOTIONS.index(emotion)\n",
    "            y = pd.DataFrame(np.ones((clip_features.shape[0], 1)) * e_idx, columns=['label'])\n",
    "            \n",
    "            f_idx = FOLDS.index(fold)\n",
    "            f = pd.DataFrame(np.ones((clip_features.shape[0], 1)) * f_idx, columns=['fold'])\n",
    "            \n",
    "            clip_features = pd.concat([clip_features, y, f], axis=1)\n",
    "            \n",
    "            X = pd.concat([X, clip_features], ignore_index=True)\n",
    "        \n",
    "    print('âˆš')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "plain-butter",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/andromeda/Temp/Crowd-Emotion/src_ml/../Features/Features.joblib']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_path = os.path.join(BASE_DIR, FEATURES_DIR, 'Features.joblib')\n",
    "joblib.dump(X, features_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "european-resource",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
